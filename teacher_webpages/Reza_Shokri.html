
<html lang="en">
<head>

<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="css/bootstrap.min.css" rel="stylesheet">
<link href="css/custom.css" rel="stylesheet">
<title>Reza SHOKRI</title>

</head>

<body>

<div class="container-fluid">
<div class="col-sm-4">

<img class="img-responsive" src="img/reza.jpg" style="height:250px;">

</div>

<div class="col-sm-4">	

<h2>Reza SHOKRI</h2><br>
<b>Dean's Chair</b><br>
Associate Professor<br>
<a href="http://www.comp.nus.edu.sg" target="_blank">CS Department, School of Computing</a><br>
<a href="http://nus.edu.sg/" target="_blank">National University of Singapore (NUS)</a><br>
<b>Data Privacy and Trustworthy Machine Learning Research Lab</b><br><br>

Part-time Researcher<br>
<a href="https://www.microsoft.com/en-us/research/group/privacy-preserving-machine-learning-innovation/" target="_blank">Microsoft</a><br>
<b>Privacy Preserving Machine Learning Group</b>

</div>

<div class="col-sm-4">
<div class="panel-body">

<br><br><br><br>
<b>Email</b>: firstname@comp.nus.edu.sg<br>
<b>Twitter</b>: <a href="https://twitter.com/rzshokri" target="_blank">@rzshokri</a><br>
<b>Phone</b>: +65-651-64464<br>
<b>Office</b>: COM2-03-60 <br>
<b>Mailing Address</b>: Dept. of Computer Science,<br>
NUS School of Computing, 13 Computing Drive,<br>
Computing 1, #03-27, Singapore 117417.        

</div></div></div>

<br>

<div class="container-fluid">
<div class="col-sm-12">
<div class="panel panel-default">
<div class="panel-body">

<p>My research is in data privacy and trustworthy machine learning. I am interested in designing methods to quantitatively measure the privacy risks of data processing algorithms, and build scalable schemes for generalizable machine learning models that are also privacy-preserving, robust, interpretable, and fair. Our research is on analyzing the trade-offs between different pillars of trust in machine learning for practical scenarios, and on resolving such conflicts with rigorous mathematical guarantees. We are currently working on many interesting problems in this domain, including trustworthy federated learning, differential privacy for machine learning, fairness versus privacy in machine learning, privacy-aware model explanations, privacy-preserving data synthesis, and quantifying privacy risks of data analytics.
	
Our research is supported by research awards and grants from Intel, Google, Facebook, VMWare, NEC, Huawei, AI Singapore, NUS, Singapore MoE, and NRF.
	
<p>I have open positions for PhD students and postdoctoral researchers. Please send me your CV and research statement.</p>

</div></div></div></div>
	
	
<div class="container-fluid">
<div class="col-sm-12">
<div class="panel panel-default">
<div class="panel-heading">

<h3 class="panel-title">
<b>Honors and Awards</b>
</h3>

</div>
<div class="panel-body">

<p><a href="https://www.intel.com/content/www/us/en/research/news/outstanding-researcher-awards-2023.html" target="_blank">Intel's 2023 Outstanding Researcher Award</a></p>

<p><a href="https://www.aysfellowship.org/announcement/2023fellows" target="_blank">Asian Young Scientist Fellowship 2023</a></p>

<p><a target="_blank" href="https://facctconference.org/2023/acceptedpapers.html">Best Paper Award at ACM Conference on Fairness, Accountability, and Transparency (FAccT) 2023
</a></p>

<p>NUS School of Computing Faculty Teaching Excellence Award 2023  
<font color="red"><b>&#10137</b></font>  Recent Student Feedback: <a target="_blank" href="files/CS5562.pdf">[CS5562-Trustworthy Machine Learning]</a>
</p>

<p><a href="https://research.fb.com/blog/2021/12/announcing-the-winners-of-the-building-tools-to-enhance-transparency-in-fairness-and-privacy-rfp/" target="_blank">Facebook Faculty Research Award 2021</a></p>

<p><a href="https://www.ieee-security.org/TC/SP2021/awards.html" target="_blank">IEEE Security and Privacy (S&P) Test-of-Time Award 2021</a></p>

<p><a href="https://www.vmware.com/company/research/faculty-programs.html#early" target="_blank">VMWare Early Career Faculty Award 2021</a></p>

<p><a href="https://www.intel.com/content/www/us/en/research/blogs/private-ai-collaborative-research-institute-launch.html" target="_blank">Intel Research Award (Private AI Collaborative Research Institute) 2021</a></p>

<p><a href="https://www.nus.edu.sg/careers/nus-programmes/pyp-fp-photo/" target="_blank">NUS Presidential Young Professorship, 2019-2023</a></p>

<p>NUS Early Career Research Award 2019</p>

<p><a href="https://petsymposium.org/award/winners.php" target="_blank">Caspar Bowden Award for Outstanding Research in Privacy Enhancing Technologies 2018</a></p>

<p>Swiss National Science Foundation Fellowship 2013</p>

<p>Runner-up for <a href="https://petsymposium.org/award/winners.php" target="_blank">PET Award for Outstanding Research in Privacy Enhancing Technologies 2012</a></p>
	
<p><a target="_blank" href=""></a></p>

</div></div></div></div>		


<div class="container-fluid">
<div class="col-sm-12">
<div class="panel panel-default">
<div class="panel-heading">

<h3 class="panel-title">
<b>Selected Research Papers</b> (see also <u><a href="http://scholar.google.com/citations?user=udlZXXcAAAAJ&hl=en" target="_blank">Google Scholar</a></u> and <u><a href="https://arxiv.org/a/shokri_r_1.html" target="_blank">arXiv</a></u>)
</h3>
	
</div>
	
<div class="panel-body">

<p>Sajjad Zarifzadeh, Philippe Liu, and Reza Shokri<br>
<font color="red"><b>&#10137</b></font> <a target="_blank" href="https://arxiv.org/pdf/2312.03262">Low-Cost High-Power Membership Inference Attacks</a>
<font color="red"><b>&#10137</b></font> [<a target="_blank" href="https://www.youtube.com/watch?v=sApgn3D8VtQ">talk</a>]<br>
<font color="red"><b>Oral</b></font> International Conference on Machine Learning (ICML), 2024<br>
</p>

<p>Jiayuan Ye, Anastasia Borovykh, Soufiane Hayou, and Reza Shokri<br>
<font color="red"><b>&#10137</b></font> <a target="_blank" href="https://arxiv.org/pdf/2309.17310.pdf">Leave-one-out Distinguishability in Machine Learning</a><br>
International Conference on Learning Representations (ICLR), 2024<br>
</p>

<p>Niloofar Mireshghallah, Hyunwoo Kim, Xuhui Zhou, Yulia Tsvetkov, Maarten Sap, Reza Shokri, and Yejin Choi<br>
<font color="red"><b>&#10137</b></font> <a target="_blank" href="https://arxiv.org/pdf/2310.17884"> Can LLMs Keep a Secret? Testing Privacy Implications of Language Models via Contextual Integrity Theory</a><br>
<font color="red"><b>Spotlight</b></font> International Conference on Learning Representations (ICLR), 2024<br>
</p>

<br>

<p>Jiayuan Ye, Zhenyu Zhu, Fanghui Liu, Reza Shokri, and Volkan Cevher<br>
<font color="red"><b>&#10137</b></font> <a target="_blank" href="https://arxiv.org/pdf/2310.20579">Initialization Matters: Privacy-Utility Analysis of Overparameterized Neural Networks</a><br>
Conference on Neural Information Processing Systems (NeurIPS), 2023<br>
Also to be Presented at the Theory and Practice of Differential Privacy (TPDP), 2023<br>
</p>

<p>Chendi Wang, Buxin Su, Jiayuan Ye, Reza Shokri, and Weijie J. Su<br>
<font color="red"><b>&#10137</b></font> <a target="_blank" href="https://arxiv.org/pdf/2310.19973">Unified Enhancement of Privacy Bounds for Mixture Mechanisms via f-Differential Privacy</a><br>
Conference on Neural Information Processing Systems (NeurIPS), 2023<br>
</p>

<p>Prakhar Ganesh, Hongyan Chang, Martin Strobel, and Reza Shokri<br>
<font color="red"><b>&#10137</b></font> <a target="_blank" href="https://arxiv.org/pdf/2307.04138.pdf">On The Impact of Machine Learning Randomness on Group Fairness</a>
<font color="red"><b>&#10137</b></font> [<a target="_blank" href="https://www.youtube.com/watch?v=QC-NyI-8i4M">talk</a> by Prakhar Ganesh]<br>
ACM Conference on Fairness, Accountability, and Transparency (FAccT), 2023<br>
<a target="_blank" href="https://facctconference.org/2023/acceptedpapers.html"><font color="red"><b>Best Paper Award</b></font></a><br>
</p>

<p>Hongyan Chang and Reza Shokri<br>
<font color="red"><b>&#10137</b></font> <a target="_blank" href="https://openreview.net/forum?id=V7CYzdruWdm">Bias Propagation in Federated Learning</a> <br>
International Conference on Learning Representations (ICLR), 2023<br>
</p>

<p>Zebang Shen, Jiayuan Ye, Anmin Kang, Hamed Hassani, and Reza Shokri<br>
<font color="red"><b>&#10137</b></font> <a target="_blank" href="https://arxiv.org/pdf/2309.05505.pdf">Share Your Representation Only: Guaranteed Improvement of the Privacy-Utility Tradeoff in Federated Learning</a> <br>
International Conference on Learning Representations (ICLR), 2023<br>
</p>

<br>

<p>Jiayuan Ye and Reza Shokri<br>
<font color="red"><b>&#10137</b></font> <a target="_blank" href="https://arxiv.org/pdf/2203.05363">Differentially Private Learning Needs Hidden State (Or Much Faster Convergence)</a> <br>
Conference on Neural Information Processing Systems (NeurIPS), 2022<br>
Also presented at the Symposium on Foundations of Responsible Computing (FORC), 2022<br>
</p>

<p>Jiayuan Ye, Aadyaa Maddi, Sasi Kumar Murakonda, Vincent Bindschaedler, and Reza Shokri<br>
<font color="red"><b>&#10137</b></font> <a target="_blank" href="https://arxiv.org/pdf/2111.09679">Enhanced Membership Inference Attacks against Machine Learning Models</a>
<font color="red"><b>&#10137</b></font> [<a target="_blank" href="https://github.com/privacytrustlab/ml_privacy_meter/tree/master/research/2022_enhanced_mia">code</a>]<br>
ACM Conference on Computer and Communications Security (CCS), 2022<br>
</p>

<p>Florian TramÃ¨r, Reza Shokri, Ayrton San Joaquin, Hoang Le, Matthew Jagielski, Sanghyun Hong, and Nicholas Carlini<br>
<font color="red"><b>&#10137</b></font> <a target="_blank" href="https://arxiv.org/pdf/2204.00032">Truth Serum: Poisoning Machine Learning Models to Reveal Their Secrets</a><br>
ACM Conference on Computer and Communications Security (CCS), 2022<br>
<b>Media</b>: 
<a target="_blank" href="https://www.theregister.com/2022/04/12/machine_learning_poisoning/">The Register</a>, 
<a target="_blank" href="https://techxplore.com/news/2022-04-involve-poisoning-machine.html">TechXplore</a>
</p>

<p>Fatemehsadat Mireshghallah, Kartik Goyal, Archit Uniyal, Taylor Berg-Kirkpatrick, and Reza Shokri<br>
<font color="red"><b>&#10137</b></font> <a target="_blank" href="https://arxiv.org/pdf/2203.03929">Quantifying Privacy Risks of Masked Language Models Using Membership Inference Attacks</a> <br>
The Conference on Empirical Methods in Natural Language Processing (EMNLP), 2022<br>
</p>

<p>Hannah Brown, Katherine Lee, Fatemehsadat Mireshghallah, Reza Shokri, and Florian Tramer<br>
<font color="red"><b>&#10137</b></font> <a target="_blank" href="https://arxiv.org/pdf/2202.05520">What Does it Mean for a Language Model to Preserve Privacy?</a><br>
ACM Conference on Fairness, Accountability, and Transparency (FAccT), 2022<br>
<b>Media</b>: 
<a target="_blank" href="https://www.technologyreview.com/2022/08/31/1058800/what-does-gpt-3-know-about-me/">MIT Technology Review</a>
</p>

<p> Neel Patel, Reza Shokri, and Yair Zick<br>
<font color="red"><b>&#10137</b></font> <a target="_blank" href="https://arxiv.org/pdf/2006.09129">Model Explanations with Differential Privacy</a><br>
ACM Conference on Fairness, Accountability, and Transparency (FAccT), 2022<br>
</p>

<br>

<p>Rishav Chourasia*, Jiayuan Ye*, and Reza Shokri<br>
<font color="red"><b>&#10137</b></font> <a target="_blank" href="https://arxiv.org/pdf/2102.05855">Differential Privacy Dynamics of Langevin Diffusion and Noisy Gradient Descent</a>
<font color="red"><b>&#10137</b></font> [<a target="_blank" href="https://slideslive.com/38969048">talk</a> by Jiayuan Ye]<br>
<font color="red"><b>Spotlight</b></font> Conference on Neural Information Processing Systems (NeurIPS), 2021<br>
</p>

<p>Hongyan Chang, and Reza Shokri<br>
<font color="red"><b>&#10137</b></font> <a target="_blank" href="https://arxiv.org/pdf/2011.03731">On the Privacy Risks of Algorithmic Fairness</a><br>IEEE European Symposium on Security and Privacy (EuroSP), 2021<br>
Also presented at <a target="_blank" href="https://www.ftc.gov/news-events/events-calendar/privacycon-2021">FTC PrivacyCon</a>, 2021<br>
</p>

<p> Reza Shokri, Martin Strobel, and Yair Zick<br>
<font color="red"><b>&#10137</b></font> <a target="_blank" href="files/Shokri-AIES2021.pdf">On the Privacy Risks of Model Explanations</a><br>AAAI/ACM Conference on AI, Ethics, and Society (AIES), 2021<br>
Also presented at <a target="_blank" href="https://www.ftc.gov/news-events/events-calendar/privacycon-2021">FTC PrivacyCon</a>, 2021<br>
<b>Media</b>: 
<a target="_blank" href="https://hbr.org/2019/12/the-ai-transparency-paradox">Harvard Business Review</a>
</p>

<p>Sasi Kumar Murakonda, Reza Shokri, and George Theodorakopoulos<br>
<font color="red"><b>&#10137</b></font> <a target="_blank" href="files/Shokri-AISTATS2021.pdf">Quantifying the Privacy Risks of Learning High-Dimensional Graphical Models</a><br>International Conference on Artificial Intelligence and Statistics (AISTATS), 2021 
</p>

<br>

<p>Hongyan Chang, Ta Duy Nguyen, Sasi Kumar Murakonda, Ehsan Kazemi, and Reza Shokri<br>
<font color="red"><b>&#10137</b></font> <a target="_blank" href="https://arxiv.org/pdf/2006.08669">On Adversarial Bias and the Robustness of Fair Machine Learning</a><br>arXiv:2006.08669, 2020<br>
</p>

<p> Te Juin Lester Tan, and Reza Shokri<br>
<font color="red"><b>&#10137</b></font> <a target="_blank" href="files/Shokri-EuroSP2020.pdf">Bypassing Backdoor Detection Algorithms in Deep Learning</a>
<font color="red"><b>&#10137</b></font> [<a target="_blank" href="https://www.youtube.com/watch?v=5k8A3DHoHVY">talk</a>]<br>IEEE European Symposium on Security and Privacy (EuroSP), 2020<br>
</p>

<p>Congzheng Song, and Reza Shokri<br>
<font color="red"><b>&#10137</b></font> <a target="_blank" href="https://arxiv.org/pdf/1909.12982">Robust Membership Encoding: Inference Attacks and Copyright Protection for Deep Learning</a><br>ACM ASIA Conference on Computer and Communications Security (ASIACCS), 2020<br>
</p>

<p>Anshul Aggarwal, Trevor Carlson, Reza Shokri, and Shruti Tople<br>
<font color="red"><b>&#10137</b></font> <a target="_blank" href="https://arxiv.org/pdf/2007.12934">SOTERIA: In Search of Efficient Neural Networks for Private Inference</a><br>arXiv:2007.12934, 2020<br>
</p>

<br>

<p> Liwei Song, Reza Shokri, and Prateek Mittal <br>
<font color="red"><b>&#10137</b></font> <a target="_blank" href="files/Shokri-CCS2019.pdf">   Privacy Risks of Securing Machine Learning Models against Adversarial Examples</a>
<font color="red"><b>&#10137</b></font> [<a href="https://dl.acm.org/action/downloadSupplement?doi=10.1145%2F3319535.3354211&file=p241-song.webm">talk</a> by L. Song]<br>
ACM Conference on Computer and Communications Security (CCS), 2019 
</p>

<p>Milad Nasr, Reza Shokri, and Amir Houmansadr<br>
<font color="red"><b>&#10137</b></font> <a target="_blank" href="files/Shokri-SP2019.pdf">Comprehensive Privacy Analysis of Deep Learning: Passive and Active White-box Inference Attacks against Centralized and Federated Learning</a> 
<font color="red"><b>&#10137</b></font> [<a target="_blank" href="https://github.com/privacytrustlab/ml_privacy_meter">code</a>] 
<font color="red"><b>&#10137</b></font> [<a target="_blank" href="https://www.youtube.com/watch?v=lzJY4BjCxTc">talk</a> by M. Nasr]<br>
IEEE Symposium on Security and Privacy (S&amp;P) -- Oakland, 2019
</p>

<p> Hongyan Chang, Virat Shejwalkar, Reza Shokri, and Amir Houmansadr <br>
<font color="red"><b>&#10137</b></font> <a target="_blank" href="https://arxiv.org/pdf/1912.11279">Cronus: Robust and Heterogeneous Collaborative Learning with Black-Box Knowledge Transfer</a><br> arXiv:1912.11279, 2019<br>
</p>

<br>

<p>Milad Nasr, Reza Shokri, and Amir Houmansadr<br>
<font color="red"><b>&#10137</b></font> <a target="_blank" href="files/Shokri-CCS2018.pdf">Machine Learning with Membership Privacy using Adversarial Regularization</a> 
<font color="red"><b>&#10137</b></font> [<a target="_blank" href="https://github.com/SPIN-UMass/ML-Privacy-Regulization">code</a>]  
<font color="red"><b>&#10137</b></font> [<a target="_blank" href="https://www.youtube.com/watch?v=53gELTL3ibA">talk</a> by A. Houmansadr]<br>
ACM Conference on Computer and Communications Security (CCS), 2018.<br>
</p>

<p>Tyler Hunt, Congzheng Song, Reza Shokri, Vitaly Shmatikov, and Emmett Witchel<br>
<font color="red"><b>&#10137</b></font> <a target="_blank" href="https://arxiv.org/pdf/1803.05961.pdf">Chiron: Privacy-preserving Machine Learning as a Service</a><br>
arXiv:1803.05961, 2018<br>
<b>Media</b>: 
<a target="_blank" href="https://www.zdnet.com/article/can-we-teach-machine-learning-privacy/">ZDNet</a>
</p>

<br>

<p>Reza Shokri, Marco Stronati, Congzheng Song, and Vitaly Shmatikov<br>
<font color="red"><b>&#10137</b></font> <a target="_blank" href="files/Shokri-SP2017.pdf">Membership Inference Attacks against Machine Learning Models</a>
<font color="red"><b>&#10137</b></font> [<a target="_blank" href="https://github.com/csong27/membership-inference">code</a>] 
<font color="red"><b>&#10137</b></font> [<a target="_blank" href="https://github.com/privacytrustlab/ml_privacy_meter">tool</a>] 
<font color="red"><b>&#10137</b></font> [<a target="_blank" href="https://github.com/privacytrustlab/datasets">datasets</a>]
<font color="red"><b>&#10137</b></font> [<a target="_blank" href="https://www.youtube.com/watch?v=rDm1n2gceJY">talk</a>]<br>
IEEE Symposium on Security and Privacy (S&amp;P) -- Oakland, 2017.<br>
<a target="_blank" href="http://petsymposium.org/award/"><font color="red"><b>The Caspar Bowden Award for Outstanding Research in Privacy Enhancing Technologies 2018</b></font></a>.<br>
</p>

<p>Vincent Bindschaedler, Reza Shokri, and Carl Gunter<br>
<font color="red"><b>&#10137</b></font> <a target="_blank" href="files/Shokri-VLDB2017.pdf">Plausible Deniability for Privacy-Preserving Data Synthesis</a>
<font color="red"><b>&#10137</b></font> [<a target="_blank" href="https://vbinds.ch/sites/default/files/Artifacts/sgf-0.10a.tgz">code</a>]<br>
VLDB Endowment International Conference on Very Large Data Bases (PVLDB), 2017.<br>
</p>

<br>

<p>Vincent Bindschaedler and Reza Shokri.<br>
<font color="red"><b>&#10137</b></font> <a target="_blank" href="files/Shokri-SP2016.pdf">Synthesizing Plausible Privacy-Preserving Location Traces</a>
<font color="red"><b>&#10137</b></font> [<a target="_blank" href="https://vbinds.ch/sites/default/files/Artifacts/sglt-v0.1a.tgz">code</a>] 
<font color="red"><b>&#10137</b></font> [<a target="_blank" href="https://www.youtube.com/watch?v=43tICnjB1Vs">talk</a> by V. Bindschaedler]<br>
IEEE Symposium on Security and Privacy (S&amp;P) -- Oakland, 2016.<br>         
</p>

<p>Reza Shokri, George Theodorakopoulos, and Carmela Troncoso<br>
<font color="red"><b>&#10137</b></font> <a target="_blank" href="files/Shokri-TOPS2016.pdf">Privacy Games along Location Traces: A Game-Theoretic Framework for Optimizing Location Privacy</a><br>
ACM Transactions on Privacy and Security (TOPS), 2016.<br>
</p>


<p>Richard McPherson, Reza Shokri, and Vitaly Shmatikov<br>
<font color="red"><b>&#10137</b></font> <a target="_blank" href="http://arxiv.org/pdf/1609.00408v2.pdf">Defeating Image Obfuscation with Deep Learning</a><br>
arXiv:1609.00408, 2016<br>
<b>Media</b>: 
<a target="_blank" href="http://www.theregister.co.uk/2016/09/05/privacyprotecting_pixellation_performs_poorly_popped_by_ai/">The Register</a>,
<a target="_blank" href="https://www.wired.com/2016/09/machine-learning-can-identify-pixelated-faces-researchers-show/">WIRED</a>, 
<a target="_blank" href="http://www.telegraph.co.uk/technology/2016/09/13/pixelated-photos-and-license-plates-can-be-unblurred-using-artif/">The Telegraph</a>,
<a target="_blank" href="http://www.bbc.co.uk/programmes/p047p4dp">BBC</a>, 
<a target="_blank" href="https://www.cs.cornell.edu/~shmat/media.html#imgobfusc">and more</a>
</p>

<br>

<p>Reza Shokri and Vitaly Shmatikov.<br>
<font color="red"><b>&#10137</b></font> <a target="_blank" href="files/Shokri-CCS2015.pdf">Privacy-Preserving Deep Learning</a> 
<font color="red"><b>&#10137</b></font> [<a target="_blank" href="files/PPDL.zip">code</a>]<br>
ACM Conference on Computer and Communications Security (CCS), 2015.<br>
(Invited to) Conference on Communication, Control, and Computing (Allerton), 2015<br>
<font color="blue"><b>Federated Learning</b></font><br>
<b>Media</b>: <a target="_blank" href="https://www.technologyreview.com/s/601294/microsoft-and-google-want-to-let-artificial-intelligence-loose-on-our-most-private-data/">MIT Technology Review</a>
</p>

<p>Reza Shokri.<br>
<font color="red"><b>&#10137</b></font> <a target="_blank" href="files/Shokri-PETS2015.pdf">Privacy Games: Optimal User-Centric Data Obfuscation</a><br>
Privacy Enhancing Technologies Symposium (PETS), 2015 
</p>

<p>Igor Bilogrevic, Kevin Huguenin, Stephan Mihaila, Reza Shokri, and Jean-Pierre Hubaux.<br>
<font color="red"><b>&#10137</b></font> <a target="_blank" href="files/Shokri-NDSS2015.pdf">Predicting Users' Motivations behind Location Check-Ins and Utility Implications of Privacy Protection Mechanisms</a> <br>
Network and Distributed System Security (NDSS) Symposium, 2015 
</p>

<p>Arthur Gervais, Reza Shokri, Adish Singla, Srdjan Capkun, and Vincent Lenders.<br>
<font color="red"><b>&#10137</b></font> <a target="_blank" href="files/Shokri-CCS2014.pdf">Quantifying Web-Search Privacy</a> 
<font color="red"><b>&#10137</b></font> [<a href="files/WebSearchPrivacy.zip">code</a>]<br>
ACM Conference on Computer and Communications Security (CCS), 2014
</p>        

<p>Reza Shokri, George Theodorakopoulos, Panos Papadimitratos, Ehsan Kazemi, and Jean-Pierre Hubaux.<br>
<font color="red"><b>&#10137</b></font> <a target="_blank" href="files/Shokri-TDSC2014.pdf">Hiding in the Mobile Crowd: Location Privacy through Collaboration</a> <br>
IEEE Transactions on Dependable and Secure Computing (TDSC), 2014
</p>

<p>Reza Shokri.<br>
<font color="red"><b>&#10137</b></font> <a target="_blank" href="files/Shokri-Thesis.pdf">Quantifying and Protecting Location Privacy</a><br>
<b>PhD Thesis</b>, EPFL, 2013
</p>

<p>Reza Shokri, George Theodorakopoulos, Carmela Troncoso, Jean-Pierre Hubaux, and Jean-Yves Le Boudec.<br>
<font color="red"><b>&#10137</b></font> <a target="_blank" href="files/Shokri-CCS2012.pdf">Protecting Location Privacy: Optimal Strategy against Localization Attacks</a>
<font color="red"><b>&#10137</b></font> [<a target="_blank" href="https://github.com/rzshokri/optimal_location_privacy">code</a>]<br>
ACM Conference on Computer and Communications Security (CCS), 2012
</p>

<p>Reza Shokri, George Theodorakopoulos, Jean-Yves Le Boudec, and Jean-Pierre Hubaux.<br>
<font color="red"><b>&#10137</b></font> <a target="_blank" href="files/Shokri-SP2011.pdf">Quantifying Location Privacy</a>
<font color="red"><b>&#10137</b></font> [<a target="_blank" href="https://github.com/rzshokri/quantifying_location_privacy">code</a>]<br>
IEEE Symposium on Security and Privacy (S&amp;P) -- Oakland, 2011<br>
<a href="https://www.ieee-security.org/TC/SP2021/awards.html" target="_blank"><font color="red"><b>IEEE Security and Privacy (S&P) Test-of-Time Award 2021</b></font></a>.<br>
<a target="_blank" href="http://petsymposium.org/2012/award/"><font color="red">Runner-up for the Outstanding Research Award in Privacy Enhancing Technologies 2012</font></a>.<br>
</p>


</div>
</div>
</div>
</div>



<div class="container-fluid">
<div class="col-sm-12">
<div class="panel panel-default">
<div class="panel-heading">
<h3 class="panel-title">
<b>Tools and Resources</b>
</h3>
</div>
<div class="panel-body">


<div class=figure style="float:left;  margin: 0.5em;padding: 0.5em;text-align: center;">
<img src="img/ml-privacy-meter.png" class="img-responsive" style="height:250px;">
<figcaption><a href="https://github.com/privacytrustlab/ml_privacy_meter" target="_blank"><b>Machine Learning Privacy Meter Tool</b></a></figcaption>
</div> 

<div class=figure style="float:left;  margin: 0.5em;padding: 0.5em;text-align: center;">
<iframe width="400" height="250" src="https://www.youtube.com/embed/DWqnKNZTz10" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<figcaption><a href="https://github.com/privacytrustlab/ml_privacy_meter" target="_blank"><b>Machine Learning Privacy Meter Tool</b></a></figcaption>
<figcaption>Article: <a href="https://arxiv.org/pdf/2007.09339" target="_blank"><b>Aiding Regulatory Compliance by Quantifying ... </b></a></figcaption>
<figcaption><a href="https://arxiv.org/pdf/2007.09339" target="_blank"><b>... the Privacy Risks of Machine Learning</b></a></figcaption>
</div> 

<div class=figure style="float:left;  margin: 0.5em;padding: 0.5em;text-align: center;">
<iframe width="400" height="250" src="https://www.youtube.com/embed/uzJUUKE6jRQ" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<figcaption><a target="_blank" href="https://trustworthy-machine-learning.github.io/"><b>Trustworthy Machine Learning</b></a></figcaption>

</figcaption>
</div> 

<div class="figure" style="float:left;  margin: 0.5em;padding: 0.5em;text-align: center;">
<iframe width="400" height="250" src="https://www.youtube-nocookie.com/embed/sqCd5A1UTrQ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<figcaption> <b>Auditing Data Privacy in Machine Learning</b></figcaption>
</div>



</div>
</div>
</div>	
</div>	


<div class="container-fluid">
<div class="col-sm-12">
<div class="panel panel-default">
<div class="panel-heading">
<h3 class="panel-title">
<b>Teaching</b>
</h3>
</div>
<div class="panel-body">
	<p><font color="red"><b>&#10137</b></font> CS5562 (Sem 1: 2023-24): <a href="courses/2023-cs5562" target="_blank">Trustworthy Machine Learning</a> <i>(robustness, privacy, and fairness in machine learning)</i></p>
<p><font color="red"><b>&#10137</b></font> CS3235 (Sem 1: 2023-24): Computer Security</p>
<p> CS5562 (Sem 1: 2022-23): <a href="https://trustworthy-machine-learning.github.io/" target="_blank">Trustworthy Machine Learning</a> <i>(robustness, privacy, and fairness in machine learning)</i></p>
<p> CS3235 (Sem 1: 2022-23): Computer Security</p>
<p> CS5562 (Sem 1: 2021-22): Trustworthy Machine Learning</p>
<p> CS3235 (Sem 1: 2021-22): Computer Security</p>
<p> CS6283 (Sem 1: 2020-21): Topics in Computer Science: Trustworthy Machine Learning</p>
<p> CS3235 (Sem 1: 2020-21): Computer Security</p>
<p> CS3235 (Sem 2: 2019-20): Computer Security <i>(secure channels, software security, OS security, privacy)</i></p>
<p> CS6231 (Sem 1: 2019-20): Topics in Computer Security: <a href="courses/2019-cs6231" target="_blank">Adversarial Machine Learning</a> <i>(privacy, robustness)</i></p>
<p> CS4257 (Sem 2: 2018-19): <a href="courses/2019-cs4257" target="_blank">Algorithmic Foundations of Privacy</a><i>(anonymous communication, data privacy, private computation)</i></p>
<p> CS6231 (Sem 1: 2018-19): An Adversarial View of Privacy <i>(inference attacks)</i></p>
<p> CS4257 (Sem 2: 2017-18): Algorithmic Foundations of Privacy <i>(anonymous communication, data privacy, private computation)</i></p>
<p> CS6101 (Sem 1: 20**): Privacy and Security in Machine Learning <i>(trustworthy machine learning)</i></p>
</div>
</div>
</div>	
</div>	



<div class="container-fluid">
<div class="col-sm-12">
<div class="panel panel-default">
<div class="panel-heading">
<h3 class="panel-title">
<b>Professional Activities</b>
</h3>
</div>
<div class="panel-body">
<b>Organizer</b>: NUS Computer Science Research Week: <a href="http://researchweek.comp.nus.edu.sg/index_Jan2019.html" target="_blank"> 2019</a>, <a href="http://researchweek.comp.nus.edu.sg/index_Jan2020.html" target="_blank">2020</a>,   <a href="http://researchweek.comp.nus.edu.sg/index_Jan2021.html" target="_blank"> 2021</a>, <font color="red"><b>&#10137</b></font>   <a href="http://researchweek.comp.nus.edu.sg/" target="_blank">2022</a> <br>
<b>Co-organizer</b>: ICLR Workshop Distributed and Private Machine Learning (DPML): <a href="https://dp-ml.github.io/2021-workshop-ICLR/" target="_blank">2021</a><br>


<br>

<b>Award committee</b> member
<ul>

<li>The Caspar Bowden Award for Outstanding Research in Privacy Enhancing Technologies:  <a href="https://petsymposium.org/award/winners.php" target="_blank">2015</a>, <a href="https://petsymposium.org/award/winners.php" target="_blank">2016</a>, <a href="https://petsymposium.org/award/winners.php" target="_blank">2019</a>,  <a href="https://petsymposium.org/award/winners.php" target="_blank">2021</a>,  <a href="https://petsymposium.org/award/cfn.php" target="_blank">2022</a> </li>

<li>CNIL-Inria Privacy Award: <a href="https://www.cnil.fr/en/launch-6th-edition-cnil-inria-privacy-award" target="_blank">2021</a></li>

</ul>

<b>Program committee</b> member
<ul>

<li><b>co-chair</b>: Shadow PC of IEEE Symposium on Security and Privacy (SP): <a href="https://www.ieee-security.org/TC/SP2021/shadowpc.html" target="_blank">2021</a></li>

<li><b>co-chair</b>: Hot Topics in Privacy Enhancing Technologies (HotPETs): <a href="http://petsymposium.org/2013/hotpets.php" target="_blank">2013</a> and <a href="http://petsymposium.org/2014/hotpets.php" target="_blank">2014</a></li>

<li>IEEE Symposium on Security and Privacy (Oakland): <a href="https://www.ieee-security.org/TC/SP2019/" target="_blank">2019</a>, <a href="https://www.ieee-security.org/TC/SP2020/" target="_blank">2020</a>,  <a href="https://www.ieee-security.org/TC/SP2021/" target="_blank">2021</a>,  <font color="red"><b>&#10137</b></font> <a href="https://www.ieee-security.org/TC/SP2023/" target="_blank">2023</a> </li>

<li>ACM Conference on Computer and Communications Security (CCS): <a href="http://www.sigsac.org/ccs/CCS2017" target="_blank">2017</a>, <a href="http://www.sigsac.org/ccs/CCS2019" target="_blank">2019</a>, <a href="https://www.sigsac.org/ccs/CCS2020/index.html" target="_blank">2020</a>,   <a href="https://www.sigsac.org/ccs/CCS2021/" target="_blank">2021</a>, <font color="red"><b>&#10137</b></font> <a href="https://www.sigsac.org/ccs/CCS2022/" target="_blank">2022</a> </li>

<li>ACM Conference on Fairness, Accountability, and Transparency (FAccT):   <font color="red"><b>&#10137</b></font>  <a href="https://facctconference.org/2022/" target="_blank">2022</a> </li>

<li>ACM CCS Workshop on Privacy-Preserving Machine Learning (PPML): <a href="https://ppml-workshop.github.io/" target="_blank">2021</a> </li>
	
<li>Deep Learning and Security workshop (DLS): <a href="https://www.ieee-security.org/TC/SPW2020/DLS/" target="_blank">2020</a>, <a href="https://www.ieee-security.org/TC/SP2021/SPW2021/dls_website/" target="_blank">2021</a>  </li>

<li>AAAI Workshop on Privacy-Preserving Artificial Intelligence (PPAI): <a href="https://www2.isye.gatech.edu/~fferdinando3/cfp/PPAI20/" target="_blank">2020</a>, <a href="https://ppai21.github.io/" target="_blank">2021</a>    </li>

<li>Privacy-Enhancing Technologies Symposium (PETS): <a href="http://petsymposium.org/2013" target="_blank">2013</a>, <a href="http://petsymposium.org/2014" target="_blank">2014</a>, <a href="http://petsymposium.org/2015" target="_blank">2015</a>, <a href="http://petsymposium.org/2017" target="_blank">2017</a>, <a href="http://petsymposium.org/" target="_blank">2019</a>, <a href="http://petsymposium.org/" target="_blank">2020</a></li>

<li>ACM ASIA Conference on Computer and Communications Security (ASIACCS): <a href="https://asiaccs2019.blogs.auckland.ac.nz/" target="_blank">2019</a>, <a href="https://asiaccs2020.cs.nthu.edu.tw" target="_blank">2020</a></li>
	
<li>ACM CCS Workshop on Theory and Practice of Differential Privacy (TPDP): <a href="https://tpdp.cse.buffalo.edu/2018/" target="_blank">2018</a>, <a href="https://tpdp.cse.buffalo.edu/2019" target="_blank">2019</a></li>

<li>USENIX Security and AI Networking Conference: <a href="https://www.usenix.org/conference/scainet19/" target="_blank">2019</a></li>

<li>USENIX Security Symposium: <a href="https://www.usenix.org/conference/usenixsecurity15" target="_blank">2015</a>,  <a href="https://www.usenix.org/conference/usenixsecurity16" target="_blank">2016</a></li>

<li>Network and Distributed System Security Symposium (NDSS): <a href="https://www.internetsociety.org/events/ndss-symposium-2016" target="_blank">2016</a>, <a href="https://www.internetsociety.org/events/ndss-symposium/ndss-symposium-2017" target="_blank">2017</a></li>

<li>IEEE European Symposium on Security and Privacy (Euro S&amp;P): <a href="http://www.ieee-security.org/TC/EuroSP2017/index.php" target="_blank">2017</a></li>

<li>ACM Conference on Security and Privacy in Wireless and Mobile Networks (WiSec): <a href="http://www.sigsac.org/wisec/WiSec2014" target="_blank">2014</a>, <a href="http://www.sigsac.org/wisec/WiSec2015" target="_blank">2015</a>, <a href="http://www.sigsac.org/wisec/WiSec2016" target="_blank">2016</a>, <a href="https://wisec18.conf.kth.se/sites/index.html" target="_blank">2018</a>

<li>Conference on Decision and Game Theory for Security (GameSec): <a href="http://www.gamesec-conf.org/2015" target="_blank">2015</a>, <a href="http://www.gamesec-conf.org/2016/" target="_blank">2016</a>, <a href="http://www.gamesec-conf.org/2018/" target="_blank">2018</a></li>

<li>International World Wide Web Conference (WWW): <a href="http://www2016.ca" target="_blank">2016</a></li>

<li>ACM Workshop on Privacy in the Electronic Society (WPES): <a href="https://hatswitch.org/wpes2012/" target="_blank">2012</a>, <a href="https://wpes15.cs.umn.edu" target="_blank">2015</a></li>

<li>ASIACCS Workshop on IoT Privacy, Trust, and Security (IoTPTS): <a href="https://sites.google.com/site/iotpts/" target="_blank">2015</a>, <a href="https://sites.google.com/site/iotpts2016/" target="_blank">2016</a></li>

<li>Workshop on Understanding and Enhancing Online Privacy (UEOP): <a href="http://sps.cs.uni-saarland.de/ueop" target="_blank"> 2016</a></li>

<li>International Workshop on Obfuscation: Science, Technology, and Theory: <a href="http://www.obfuscationworkshop.io" target="_blank">2017</a></li>

<li>International Conference on Privacy, Security and Trust (PST): <a href="http://pst2014.ryerson.ca" target="_blank">2014</a></li>
</ul>
</div>
</div>
</div>
</div>


<div class="container-fluid">
<div class="col-sm-12">
<div class="panel panel-default">
<div class="panel-heading">
<h3 class="panel-title">
<a id="talks"></a><b>Invited Talks and Visits</b>
</h3>
</div>
<div class="panel-body">

<p><b>Tutorial: <a href="ml-privacy-tutorial.html" target="_blank">Auditing Data Privacy in Machine Learning: A Comprehensive Introduction</a></b>, ACM CCS, November 2022</p>

<p><b>Tutorial: <a href="" target="_blank">Quantitative Reasoning About Data Privacy in Machine Learning</a></b> (with <a href="https://sites.google.com/view/chuanguo" target="_blank">Chuan Guo</a>), ICML, July 2022  <a href="https://icml.cc/virtual/2022/tutorial/18439" target="_blank"><img src="img/y.png" style="height:20px;"></a> </p>

<p>Auditing Data Privacy for Machine Learning, <a href="https://www.usenix.org/conference/enigma2022" target="_blank">Usenix Enigma Conference</a>, February 2022  <a href="https://www.youtube.com/watch?v=sqCd5A1UTrQ" target="_blank"><img src="img/y.png" style="height:20px;"></a> </p>


<p>Data Privacy and Trustworthy Machine Learning, <a href="https://sites.google.com/view/rcv-cvpr2021" target="_blank">CVPR Workshop on Responsible Computer Vision</a>, June 2021 <a href="https://www.youtube.com/watch?v=VEWtjtrg6Gg" target="_blank"><img src="img/y.png" style="height:20px;"></a> </p>

<p>Data Privacy in Machine Learning, Google APAC Academic Research Talk Series, April 2021</p>


<p><a href="files/Shokri-DP-Dynamics-ML-slides.pdf" target="_blank"><b>Modeling Privacy Erosion: Differential Privacy Dynamics in Machine Learning</b></a>, <a target="_blank" href="https://ppai21.github.io/">AAAI Workshop on Privacy-Preserving Artificial Intelligence (PPAI)</a>, February 2021 <a href="https://youtu.be/e7aUGNKg4vA" target="_blank"><img src="img/y.png" style="height:20px;"></a> </p>

<p>Privacy at the Intersection of Trustworthy Machine Learning <a target="_blank" href="https://ppml-workshop.github.io/">NeurIPS Workshop on Privacy Preserving Machine Learning (PriML and PPML Joint Edition)</a>, December 2020  <a href="https://slideslive.com/38938419" target="_blank"><img src="img/y.png" style="height:20px;"></a> </p>

<p><a target="_blank" href="https://ml-retrospectives.github.io/neurips2020/">NeurIPS Workshop on ML Retrospectives, Surveys & meta-Analyses (ML- RSA)</a>, December 2020</p>

<p><a href="files/Shokri-ML-Data-Privacy-slides.pdf" target="_blank"><b>Data Privacy in Machine Learning</b></a>, <a target="_blank" href="https://sites.google.com/view/privatenlp/">EMNLP Workshop on Privacy in Natural Language Processing (PrivateNLP)</a>, November 2020</p>

<p>In Search of Lost Performance in Privacy-Preserving Deep Learning, <a target="_blank" href="https://cvcops20.cispa.saarland/">ECCV Workshop on The Bright and Dark Sides of Computer Vision: Challenges and Opportunities for Privacy and Security (CV-COPS)</a>, August 2020</p>
	
<p>Trustworthy Machine Learning, <a target="_blank" href="http://cs.ipm.ac.ir/asoc2020/">IPM Advanced School on Computing: Artificial Intelligence</a>, August 2020</p>

<p>Trustworthy Machine Learning, <a target="_blank" href="https://aisummerschool.aisingapore.org/">AI Singapore Summer School</a>, August 2020</p>

<p>Cronus: Robust Knowledge Transfer for Federated Learning, <a target="_blank" href="">Google Workshop on Federated Learning and Analytics</a>, July 2020 <a href="https://www.youtube.com/watch?v=GJyXf2xtTo4" target="_blank"><img src="img/y.png" style="height:20px;"></a></p>
	
<p>Data Privacy in Machine Learning, <a target="_blank" href="https://fpf.org/2020/07/01/fpf-webinar-explores-the-future-of-privacy-preserving-machine-learning/">Future of Privacy Forum webinar on Privacy Preserving Machine Learning: New Research on Data and Model Privacy</a>, June 2020</p>

<p>[Keynote] <a target="_blank" href="https://idrbt.ac.in/ICISS-2019/">International Conference on Information Systems Security (ICISS)</a>, India, December 2019</p>
<p><a target="_blank" href="https://datatracker.ietf.org/meeting/106/materials/agenda-106-pearg-01">IETF Privacy Enhancements and Assessments Research Group</a>, Singapore, November 2019</p>
<p><a target="_blank" href="http://aisummerschool.aisingapore.org/">AI Singapore Summer School</a>, July 2019</p>
<p><a target="_blank" href="https://www.inria.fr/centre/grenoble">INRIA Grenoble</a>, France, July 2019</p>
<p><a target="_blank" href="https://www.inria.fr/centre/saclay">INRIA Saclay</a> and <a target="_blank" href="https://www.lix.polytechnique.fr/">LIX</a>, France, July 2019</p>
<p>[Keynote] <a target="_blank" href="https://www.ihmmsec.org">ACM Workshop on Information Hiding and Multimedia Security (IH&MMSec)</a>, Paris, France, July 2019</p>
<p><a target="_blank" href="https://suri.epfl.ch/">EPFL Summer Research Institute</a>, Switzerland, June 2019</p>
<p><a target="_blank" href="https://formal-paris-saclay.fr/">ForMaL: DigiCosme Spring School on Formal Methods and Machine Learning</a>, ENS Paris-Saclay, France, June 2019</p>
<p><a target="_blank" href=""></a></p>
</div>
</div>
</div>	
</div>	




<div class="container-fluid">
<div class="col-sm-12">
<div class="panel panel-default">
<div class="panel-heading">
<h3 class="panel-title">
<b>Researchers</b>
</h3>
</div>
<div class="panel-body">

<div class=figure style="float:left;  margin: 0.5em;padding: 0.5em;text-align: center;">
<img src="img/Reza-lab.jpg" class="img-responsive" style="height:470px;">
<figcaption>(Dec 2023)</figcaption>
</div> 

<div class=figure style="float:left;  margin: 0.5em;padding: 0.5em;text-align: center;">
<img src="img/hongyan.jpg" class="img-responsive" style="height:200px;">
<figcaption><a href="https://www.comp.nus.edu.sg/~hongyan/" target="_blank">Hongyan Chang</a></figcaption>
<figcaption>(PhD Student)</figcaption>
</div> 

<div class=figure style="float:left;  margin: 0.5em;padding: 0.5em;text-align: center;">
<img src="img/martin.jpg" class="img-responsive" style="height:200px;">
<figcaption><a href="https://www.comp.nus.edu.sg/~mstrobel/" target="_blank" >Martin Strobel</a></figcaption>
<figcaption>(PhD Student)</figcaption>
</div> 

<div class=figure style="float:left;  margin: 0.5em;padding: 0.5em;text-align: center;">
<img src="img/jiayuan.jpg" class="img-responsive" style="height:200px;">
<figcaption><a href="https://www.comp.nus.edu.sg/~jiayuan/" target="_blank">Jiayuan Ye</a></figcaption>
<figcaption>(PhD Student)</figcaption>
</div> 

<div class=figure style="float:left;  margin: 0.5em;padding: 0.5em;text-align: center;">
<img src="img/jiashu.jpg" class="img-responsive" style="height:200px;">
<figcaption><a href="" target="_blank">Jiashu Tao</a></figcaption>
<figcaption>(PhD Student)</figcaption>
</div> 

<div class=figure style="float:left;  margin: 0.5em;padding: 0.5em;text-align: center;">
<img src="img/zitai.jpeg" class="img-responsive" style="height:200px;">
<figcaption><a href="" target="_blank">Zitai Chen</a></figcaption>
<figcaption>(PhD Student)</figcaption>
</div> 

<div class=figure style="float:left;  margin: 0.5em;padding: 0.5em;text-align: center;">
<img src="img/yao.jpg" class="img-responsive" style="height:200px;">
<figcaption><a href="" target="_blank">Yao Tong</a></figcaption>
<figcaption>(PhD Student)</figcaption>
</div> 

</div>
</div>
</div>
</div>				


<div class="container-fluid">
<div class="col-sm-12">
<div class="panel panel-default">
<div class="panel-heading">
	<h3 class="panel-title">
		<b>Alumni</b>
	</h3>
</div>
<div class="panel-body">

<div class=figure style="float:left;  margin: 0.5em;padding: 0.5em;text-align: center;">
<img src="img/philippe.jpg" class="img-responsive" style="height:200px;">
<figcaption><a href="">Philippe Liu</a></figcaption>
<figcaption>(Master's Student): 2022</figcaption>
<figcaption>(Research Assistant): 2023</figcaption>
</div> 


<div class=figure style="float:left;  margin: 0.5em;padding: 0.5em;text-align: center;">
<img src="img/yaxihu.jpeg" class="img-responsive" style="height:200px;">
<figcaption><a href="https://www.comp.nus.edu.sg/~yaxi/" target="_blank">Yaxi Hu</a></figcaption>
<figcaption>(Intern) 2023</figcaption>
</div> 

<div class=figure style="float:left;  margin: 0.5em;padding: 0.5em;text-align: center;">
<img src="img/estelle.jpg" class="img-responsive" style="height:200px;">
<figcaption><a href="https://www.comp.nus.edu.sg/~estelle/" target="_blank">Estelle Zheng</a></figcaption>
<figcaption>(Masters Student): 2023</figcaption>
</div> 

<div class=figure style="float:left;  margin: 0.5em;padding: 0.5em;text-align: center;">
<img src="img/victor.jpg" class="img-responsive" style="height:200px;">
<figcaption><a href="">Victor Masiak</a></figcaption>
<figcaption>(Master's Student): 2022</figcaption>
</div> 

<div class=figure style="float:left;  margin: 0.5em;padding: 0.5em;text-align: center;">
<img src="img/prakhar.jpg" class="img-responsive" style="height:200px;">
<figcaption><a href="">Prakhar Ganesh</a></figcaption>
<figcaption>(Master's Student): 2022</figcaption>
</div> 

<div class=figure style="float:left;  margin: 0.5em;padding: 0.5em;text-align: center;">
<img src="img/aadyaa.jpg" class="img-responsive" style="height:200px;">
<figcaption><a href="">Aadyaa Maddi</a></figcaption>
<figcaption>(Research Assistant) 2020-22</figcaption>
<figcaption>(Undergrad Student): 2019-20</figcaption>
</div> 

	<div class=figure style="float:left;  margin: 0.5em;padding: 0.5em;text-align: center;">
	<img src="img/duy.jpg" class="img-responsive" style="height:200px;">
	<figcaption><a href="">Ta Duy Nguyen</a></figcaption>
	<figcaption>(Research Assistant) 2019-21</figcaption>
	</div> 
	
	<div class=figure style="float:left;  margin: 0.5em;padding: 0.5em;text-align: center;">
	<img src="img/sasi.jpg" class="img-responsive" style="height:200px;">
	<figcaption><a href="">Sasi Kumar Murakonda</a></figcaption>
	<figcaption>(Research Assistant) 2018-20</figcaption>
	</div> 

	<div class=figure style="float:left;  margin: 0.5em;padding: 0.5em;text-align: center;">
	<img src="img/neel.jpg" class="img-responsive" style="height:200px;">
	<figcaption><a href="">Neel Patel</a></figcaption>
	<figcaption>(Research Assistant) 2019-20</figcaption>
	</div> 

	<div class=figure style="float:left;  margin: 0.5em;padding: 0.5em;text-align: center;">
	<img src="img/anshul.jpg" class="img-responsive" style="height:200px;">
	<figcaption><a href="">Anshul Aggarwal</a></figcaption>
	<figcaption>(Master's Student) 2019</figcaption>
	<figcaption>(Research Assistant) 2020</figcaption>
	</div> 

	<div class=figure style="float:left;  margin: 0.5em;padding: 0.5em;text-align: center;">
	<img src="img/mihir.jpg" class="img-responsive" style="height:200px;">
	<figcaption><a href="">Mihir Khandekar</a></figcaption>
	<figcaption>(Master's Student) 2020</figcaption>
	</div> 


<div class=figure style="float:left;  margin: 0.5em;padding: 0.5em;text-align: center;">
<img src="img/ayrton.jpg" class="img-responsive" style="height:200px;">
<figcaption><a href="">Ayrton San Joaquin</a></figcaption>
<figcaption>(Undergrad Student) 2021/22</figcaption>
</div> 


<div class=figure style="float:left;  margin: 0.5em;padding: 0.5em;text-align: center;">
<img src="img/anmin.jpg" class="img-responsive" style="height:200px;">
<figcaption><a href="">Anmin Kang</a></figcaption>
<figcaption>(Master's Student) 2021</figcaption>
<figcaption>(Undergrad Student): 2019/20</figcaption>
</div> 

		
				<div class=figure style="float:left;  margin: 0.5em;padding: 0.5em;text-align: center;">
	<img src="img/yongler.jpg" class="img-responsive" style="height:200px;">
		<figcaption><a href="">Yong Ler Lee</a></figcaption>
		<figcaption>(Undergrad Student): 2019/20</figcaption>
	</div> 

				<div class=figure style="float:left;  margin: 0.5em;padding: 0.5em;text-align: center;">
	<img src="img/qinghao.jpg" class="img-responsive" style="height:200px;">
		<figcaption><a href="">Qinghao Chu</a></figcaption>
		<figcaption>(Undergrad Student): 2019/20</figcaption>
	</div> 

				<div class=figure style="float:left;  margin: 0.5em;padding: 0.5em;text-align: center;">
	<img src="img/alexander.jpg" class="img-responsive" style="height:200px;">
		<figcaption><a href="">Guo Sheng Alexander Lee</a></figcaption>
		<figcaption>(Undergrad Student) 2019/20</figcaption>
	</div> 

				<div class=figure style="float:left;  margin: 0.5em;padding: 0.5em;text-align: center;">
	<img src="img/lester.jpg" class="img-responsive" style="height:200px;">
		<figcaption><a href="">Te Juin Lester Tan</a></figcaption>
		<figcaption>(Undergrad Student) 2018/19</figcaption>
	</div> 




</div>
</div>
</div>
</div>				





<script type="text/javascript" src="/_Incapsula_Resource?SWJIYLWA=719d34d31c8e3a6e6fffd425f7e032f3&ns=2&cb=1214505137" async></script></body>

</html>

